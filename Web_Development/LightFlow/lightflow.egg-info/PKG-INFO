Metadata-Version: 2.4
Name: lightflow
Version: 0.1.0
Summary: A lightweight parallel task pipeline framework
Author: Shivansh Katiyar
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: PyYAML>=6.0
Requires-Dist: click>=8.0.0
Requires-Dist: rich>=13.0.0
Requires-Dist: networkx>=3.0
Requires-Dist: graphviz>=0.20
Requires-Dist: pytest>=7.0.0
Requires-Dist: pytest-cov>=4.0.0
Dynamic: author
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# ⚙️ LightFlow: A Lightweight Parallel Task Pipeline Framework

> A minimal, Pythonic alternative to Airflow — run dependent tasks in parallel using threads or processes, from a simple YAML workflow file.

---

## 📌 Project Overview

**LightFlow** is a lightweight, dependency-aware parallel task execution framework written in Python. It allows users to define workflows with steps and dependencies via a simple `YAML` or `JSON` file and executes them using multiprocessing or multithreading. It features real-time visualization of the **DAG (Directed Acyclic Graph)**, persistent checkpointing, failure logging, and retry logic.

Ideal for small-scale automation pipelines, CI tasks, ML model workflows, and more — without needing a full Apache Airflow setup.

---

## 🎯 Key Features

- 🧩 **Workflow as Code**  
  Define tasks, dependencies, and execution strategies in a YAML or JSON file.

- 🚀 **Parallel Execution**  
  Run independent tasks concurrently using `concurrent.futures` or `multiprocessing`.

- 🔗 **DAG Visualization**  
  Generate and render task graphs using `graphviz` or `networkx`.

- 🛠️ **Failure Recovery & Checkpointing**  
  Save progress, skip completed tasks, and retry failed ones on rerun.

- 📜 **Rich Logging**  
  Task stdout/stderr logs saved individually with timestamps.

- 📦 **Plugin Architecture**  
  Easily define custom task types (e.g., shell commands, Python scripts, HTTP calls, etc.).

---

## 🔧 Sample Workflow YAML

```yaml
workflow_name: daily_model_pipeline
tasks:
  fetch_data:
    run: python scripts/fetch.py
  preprocess:
    run: python scripts/clean.py
    depends_on: [fetch_data]
  train_model:
    run: python scripts/train.py
    depends_on: [preprocess]
  evaluate:
    run: python scripts/eval.py
    depends_on: [train_model]
  notify:
    run: curl -X POST https://webhook.site/send
    depends_on: [evaluate]
settings:
  max_parallel_tasks: 3
  retries: 2
  log_dir: logs/
```

---

## 🧩 Tech Stack

| Purpose | Library / Tool |
|---------|----------------|
| Task Execution | multiprocessing, threading, asyncio |
| DAG Parsing | networkx, pygraphviz |
| CLI Interface | click |
| Logging | logging, rich |
| YAML Support | PyYAML |
| Checkpointing | JSON snapshot |

---

## 📂 Project Structure

```
lightflow/
├── engine/
│   ├── executor.py         # Thread/Process/Async manager
│   ├── dag_builder.py      # Builds and validates DAG
│   ├── checkpoint.py       # Saves and loads execution state
│   ├── logger.py           # Rich logging interface
├── parser/
│   └── workflow_loader.py  # Loads YAML/JSON workflow
├── cli/
│   └── main.py             # Entry point for CLI
├── plugins/
│   └── shell_task.py       # Executes shell tasks
│   └── python_task.py      # Executes Python functions
├── visuals/
│   └── dag_viewer.py       # Generates DAG PNG/SVG
├── examples/
│   └── basic_workflow.yaml
├── tests/
│   └── test_*.py           # Unit tests
├── README.md
└── requirements.txt
```

---

## 💻 CLI Commands

```bash
# Run a workflow
lightflow run examples/basic_workflow.yaml

# Visualize DAG
lightflow dag --file examples/basic_workflow.yaml --output dag.svg

# Show task logs
lightflow logs --task train_model

# Resume failed workflow
lightflow resume examples/basic_workflow.yaml

# Validate workflow
lightflow validate examples/basic_workflow.yaml

# Create workflow template
lightflow template my_workflow

# List checkpoints
lightflow list-checkpoints workflow_name

# Clear checkpoints
lightflow clear workflow_name
```

---

## 🔐 Checkpointing

- Each task's completion status is stored in a `.lightflow-checkpoint.json` file
- On rerun, completed tasks are skipped
- Failures are logged with exit codes and stack traces

---

## 📈 Future Enhancements

- [ ] Web dashboard for live task monitoring
- [ ] Cron-based scheduling
- [ ] Docker container support for task isolation
- [ ] GraphQL API to control tasks remotely
- [ ] Retry strategies per task (exponential backoff)

---

## 📜 License

MIT License — built for devs, data scientists, and tinkerers.

---

## 🤝 Contributing

Open to PRs for:

- More task plugin types (e.g., SQL, HTTP, Lambda)
- DAG visual enhancements
- Async I/O support

---

## 🔗 Related Projects

- [Apache Airflow](https://airflow.apache.org/)
- [Luigi](https://github.com/spotify/luigi)
- [Prefect](https://www.prefect.io/)

---

## 🚀 Quick Start

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd LightFlow

# Install dependencies
pip install -r requirements.txt

# Install in development mode
pip install -e .
```

### Basic Usage

1. **Create a workflow file** (`my_workflow.yaml`):
```yaml
workflow_name: my_first_workflow
tasks:
  hello:
    run: echo "Hello, LightFlow!"
    type: shell
    depends_on: []
  world:
    run: echo "World!"
    type: shell
    depends_on: [hello]
settings:
  max_parallel_tasks: 2
```

2. **Run the workflow**:
```bash
lightflow run my_workflow.yaml
```

3. **Visualize the DAG**:
```bash
lightflow dag --file my_workflow.yaml --output workflow.svg
```

### Examples

Check out the `examples/` directory for sample workflows:

- `basic_workflow.yaml` - Simple linear workflow
- `python_workflow.yaml` - Python-based data processing
- `parallel_workflow.yaml` - Parallel task execution

---

## 🧪 Testing

Run the test suite:

```bash
# Install test dependencies
pip install pytest pytest-cov

# Run tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=lightflow --cov-report=html
```

---

## 📊 Performance

LightFlow is designed for small to medium-scale workflows:

- **Recommended**: Up to 50 tasks per workflow
- **Maximum**: 100+ tasks (with proper resource management)
- **Execution modes**: Thread, Process, Async
- **Parallelism**: Configurable worker pools

---

## 🔧 Configuration

### Task Types

Currently supported task types:

- **shell**: Execute shell commands
- **python**: Execute Python code

### Settings

- `max_parallel_tasks`: Maximum concurrent tasks (default: 4)
- `retries`: Number of retry attempts (default: 0)
- `log_dir`: Directory for log files (default: "logs/")

---

## 🐛 Troubleshooting

### Common Issues

1. **Graphviz not available**: Install with `pip install graphviz`
2. **Permission errors**: Ensure write permissions for log and checkpoint directories
3. **Task failures**: Check task output in log files

### Debug Mode

Enable debug logging:

```bash
lightflow run workflow.yaml --debug
```

---

## 📝 Changelog

### v0.1.0
- Initial release
- Basic workflow execution
- YAML/JSON support
- DAG visualization
- Checkpointing system
- CLI interface

---

## 📞 Support

- **Issues**: Create an issue on GitHub
- **Discussions**: Use GitHub Discussions
- **Documentation**: Check the examples and tests

---

## 🙏 Acknowledgments

- Inspired by Apache Airflow
- Built with Python's concurrent.futures
- Visualization powered by Graphviz
- Rich CLI experience with Click

---

Let me know if you'd like:
- A sample Python workflow to demo
- DAG SVG rendering with Graphviz
- Dockerized setup for easier use 
